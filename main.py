from PySide2.QtUiTools import loadUiType, QUiLoader
from PySide2.QtCore import QFile, Qt, QTimer, QDateTime
from PySide2.QtGui import QIcon, QImage, QPixmap
from PySide2.QtWidgets import (QWidget, QTableWidgetItem, QApplication,
                               QDialog, QVBoxLayout, QLabel, QPushButton,
                               QGroupBox, QHBoxLayout, QFrame)
import cv2
import numpy as np
import os
from SVM import SVMBinaryClassifier

from sklearn.model_selection import cross_val_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler
from skimage.feature import hog


# class SimplesvmClassifier:
#     def __init__(self):
#         self.X = []  # ç‰¹å¾å‘é‡
#         self.y = []  # æ ‡ç­¾
#         self.model = KNeighborsClassifier(n_neighbors=3)  # åˆå§‹åŒ–svmæ¨¡å‹ï¼Œé»˜è®¤é‚»å±…æ•°ä¸º3
#         self.scaler = StandardScaler()  # ç”¨äºæ•°æ®æ ‡å‡†åŒ–
#         self.trained = False
#
#     def extract_features(self, image_path):
#         """æå–HOGç‰¹å¾"""
#         img = cv2.imread(image_path)
#         img = cv2.resize(img, (100, 100))
#         gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
#         features = hog(gray,
#                        orientations=9,
#                        pixels_per_cell=(8, 8),
#                        cells_per_block=(2, 2),
#                        visualize=False)
#         return features
#
#     def add_sample(self, image_path, label):
#         """æ·»åŠ æ ·æœ¬ï¼ˆç‰¹å¾ + æ ‡ç­¾ï¼‰"""
#         features = self.extract_features(image_path)
#         self.X.append(features)
#         self.y.append(label)
#         self.trained = False  # æ–°å¢æ ·æœ¬åéœ€é‡æ–°è®­ç»ƒ
#
#     def train(self):
#         if len(self.X) < 2:
#             raise ValueError("è‡³å°‘éœ€è¦ä¸¤ä¸ªæ ·æœ¬æ‰èƒ½è®­ç»ƒæ¨¡å‹")
#
#         X_scaled = self.scaler.fit_transform(self.X)
#         self.model.fit(X_scaled, self.y)
#         self.trained = True
#
#     def predict(self, image_path):
#         """é¢„æµ‹æ ·æœ¬ç±»åˆ«"""
#         if not self.trained:
#             self.train()  # è‹¥æœªè®­ç»ƒåˆ™å…ˆè®­ç»ƒæ¨¡å‹
#
#         features = self.extract_features(image_path)
#         features_scaled = self.scaler.transform([features])
#         return self.model.predict(features_scaled)[0]
#
#     def evaluate_accuracy(self):
#         if len(self.X) < 2:
#             raise ValueError("è‡³å°‘éœ€è¦ä¸¤ä¸ªæ ·æœ¬æ‰èƒ½è¯„ä¼°")
#         if not self.trained:
#             self.train()
#
#             # ä½¿ç”¨å·²æ‹Ÿåˆçš„scalerè¿›è¡Œè½¬æ¢
#         X_scaled = self.scaler.transform(self.X)
#
#         # ä½¿ç”¨äº¤å‰éªŒè¯è¯„ä¼°æ¨¡å‹
#         scores = cross_val_score(self.model, X_scaled, self.y, cv=5)
#         return scores.mean()

class Gui(QWidget):
    def __init__(self):
        super().__init__()
        QtFileObj = QFile("recognize.ui")
        QtFileObj.open(QFile.ReadOnly)
        QtFileObj.close()
        self.ui = QUiLoader().load(QtFileObj)
        self.ui.pushButton.setText("capture")
        self.ui.pushButton.clicked.connect(self.capture_photo)

        self.training_dir = "training_data"  # è®­ç»ƒæ•°æ®æ ¹ç›®å½•
        self.clear_training_data()
        os.makedirs(self.training_dir, exist_ok=True)  # åˆ›å»ºæ–‡ä»¶å¤¹
        self.photo_path = ""
        self.mode = "annotation"

        self.svm = SVMBinaryClassifier()
        self.ui.photoLabel = self.ui.findChild(QLabel, "photoLabel")
        self.ui.photoLabel.setText("æ‹æ‘„çš„ç…§ç‰‡å°†æ˜¾ç¤ºåœ¨è¿™é‡Œ")
        self.ui.photoLabel.setAlignment(Qt.AlignCenter)
        self.ui.photoLabel.setMinimumSize(320, 240)
        self.ui.resultGroupBox = self.ui.findChild(QGroupBox, "resultGroupBox")
        self.ui.resultLayout = self.ui.findChild(QVBoxLayout, "resultLayout")
        self.ui.resultLabel = self.ui.findChild(QLabel, "resultLabel")
        self.ui.resultLabel.setText("ç­‰å¾…æ“ä½œ...")
        self.ui.resultLabel.setAlignment(Qt.AlignCenter)
        self.ui.resultLabel.setStyleSheet("font-size: 16px; font-weight: bold;")
        if self.ui.resultLayout:
            self.ui.resultLayout.addWidget(self.ui.resultLabel)

        # # å˜é‡å®šä¹‰ã€uiç»„ä»¶å¯¹è±¡å±æ€§è®¾ç½®
        # self.index = 0
        # self.ui.tableWidgetAnswer.horizontalHeader().setVisible(True)  # è®¾ç½®tableWidgetç»„ä»¶çš„æ ‡é¢˜æ˜¾ç¤ºä¸ºTrue
        # self.ui.pushButton.clicked.connect(self.rename)  # ç»‘å®šæŒ‰é’®çš„æ–¹æ³•
        self.cap = cv2.VideoCapture(0)  # 0 is the default camera
        self.timer = QTimer(self)
        self.timer.timeout.connect(self.update_camera_view)
        self.timer.start(30)
        # self.ui.label.setText("jo")
        self.ui.modeButton = QPushButton("åˆ‡æ¢åˆ°è¯†åˆ«æ¨¡å¼")
        self.ui.modeButton.clicked.connect(self.toggle_mode)
        self.ui.verticalLayout.addWidget(self.ui.modeButton)
        # self.ui.photoLabel.setMinimumSize(320, 240)
        # self.ui.photoLabel.setFrameShape(QFrame.StyledPanel)  # æ·»åŠ è¾¹æ¡†ä»¥ä¾¿äºè°ƒè¯•
        # self.ui.photoLabel.setText("æ‹æ‘„çš„ç…§ç‰‡å°†æ˜¾ç¤ºåœ¨è¿™é‡Œ")

    def clear_training_data(self):
        print("æ­£åœ¨æ¸…ç†ä¹‹å‰çš„è®­ç»ƒæ•°æ®...")
        try:
            if os.path.exists(self.training_dir):
                # åˆ é™¤ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶å’Œå­ç›®å½•
                for item in os.listdir(self.training_dir):
                    item_path = os.path.join(self.training_dir, item)
                    if os.path.isfile(item_path):
                        os.remove(item_path)
                    elif os.path.isdir(item_path):
                        # é€’å½’åˆ é™¤å­ç›®å½•
                        for sub_item in os.listdir(item_path):
                            sub_path = os.path.join(item_path, sub_item)
                            if os.path.isfile(sub_path):
                                os.remove(sub_path)
                        os.rmdir(item_path)
                print("è®­ç»ƒæ•°æ®æ¸…ç†å®Œæˆ")
            else:
                print("è®­ç»ƒæ•°æ®æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œè·³è¿‡æ¸…ç†")
        except Exception as e:
            print(f"æ¸…ç†è®­ç»ƒæ•°æ®æ—¶å‡ºé”™: {e}")

    def rename(self):
        ret, frame = self.cap.read()
        if ret:
            frame = cv2.flip(frame, 1)
            # Convert the frame to RGB
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            h, w, ch = frame.shape
            bytes_per_line = ch * w
            qimg = QImage(frame.data, w, h, bytes_per_line, QImage.Format_RGB888)
            pixmap = QPixmap.fromImage(qimg)
            self.ui.label.setPixmap(pixmap)

    def update_camera_view(self):
        ret, frame = self.cap.read()
        if ret:
            frame = cv2.flip(frame, 1)
            # Convert the frame to RGB
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            h, w, ch = frame.shape
            bytes_per_line = ch * w
            qimg = QImage(frame.data, w, h, bytes_per_line, QImage.Format_RGB888)
            pixmap = QPixmap.fromImage(qimg)
            self.ui.label.setPixmap(pixmap)

    def capture_photo(self):
        ret, frame = self.cap.read()
        if ret:
            # ========== æ–°å¢ï¼šç”Ÿæˆå”¯ä¸€æ–‡ä»¶å ==========
            timestamp = QDateTime.currentDateTime().toString("yyyyMMdd_HHmmss.zzz")
            self.photo_path = f"{self.training_dir}/photo_{timestamp}.jpg"

            # ä¿å­˜ç…§ç‰‡ï¼ˆä¸è¦†ç›–ï¼‰
            cv2.imwrite(self.photo_path, frame)
            print(f"ç…§ç‰‡å·²ä¿å­˜ï¼š{self.photo_path}")

            # æ˜¾ç¤ºç…§ç‰‡
            pixmap = QPixmap(self.photo_path)
            if not pixmap.isNull():
                scaled_pixmap = pixmap.scaled(
                    self.ui.photoLabel.width(),
                    self.ui.photoLabel.height(),
                    Qt.KeepAspectRatio,
                    Qt.SmoothTransformation
                )
                self.ui.photoLabel.setPixmap(scaled_pixmap)
            else:
                print("é”™è¯¯ï¼šæ— æ³•åŠ è½½ç…§ç‰‡ï¼")

            if self.mode == "annotation":
                self.show_annotation_dialog()
            else:
                self.perform_recognition()

    def toggle_mode(self):
        if self.mode == "recognition":
            self.mode = "annotation"
            self.ui.modeButton.setText("åˆ‡æ¢åˆ°è¯†åˆ«æ¨¡å¼")
            self.ui.resultLabel.setText("å½“å‰æ¨¡å¼ï¼šæ ‡æ³¨")
        else:
            self.mode = "recognition"
            self.ui.modeButton.setText("åˆ‡æ¢åˆ°æ ‡æ³¨æ¨¡å¼")
            self.ui.resultLabel.setText("å½“å‰æ¨¡å¼ï¼šè¯†åˆ«")
            try:
                accuracy = self.svm.evaluate_accuracy()
                print(f"æ¨¡å‹å½“å‰å‡†ç¡®åº¦ï¼š{accuracy}")
            except ValueError as e:
                print(e)

    def show_annotation_dialog(self):
        dialog = QDialog(self)
        dialog.setWindowTitle("æ ‡æ³¨ç…§ç‰‡")
        dialog.setMinimumWidth(300)

        layout = QVBoxLayout(dialog)

        # æ˜¾ç¤ºç…§ç‰‡é¢„è§ˆ
        photo_label = QLabel()
        if os.path.exists(self.photo_path):
            pixmap = QPixmap(self.photo_path)
            scaled_pixmap = pixmap.scaled(300, 200, Qt.KeepAspectRatio)
            photo_label.setPixmap(scaled_pixmap)
        else:
            photo_label.setText("ç…§ç‰‡åŠ è½½å¤±è´¥")
        layout.addWidget(photo_label)

        # æ·»åŠ æ ‡æ³¨é€‰é¡¹
        label = QLabel("è¿™æ˜¯çŒ«è¿˜æ˜¯ç‹—ï¼Ÿ")
        layout.addWidget(label)

        button_layout = QHBoxLayout()

        cat_button = QPushButton("ğŸ± çŒ«")
        cat_button.setStyleSheet("padding: 10px; font-size: 14px;")
        cat_button.clicked.connect(lambda: self.save_annotation("cat", dialog))
        button_layout.addWidget(cat_button)

        dog_button = QPushButton("ğŸ¶ ç‹—")
        dog_button.setStyleSheet("padding: 10px; font-size: 14px;")
        dog_button.clicked.connect(lambda: self.save_annotation("dog", dialog))
        button_layout.addWidget(dog_button)

        layout.addLayout(button_layout)

        dialog.exec_()

    def save_annotation(self, label, dialog):
        if not self.photo_path:
            self.ui.resultLabel.setText("é”™è¯¯ï¼šæœªæ•è·ç…§ç‰‡")
            dialog.close()
            return

            # ========== æ–°å¢ï¼šæŒ‰ç±»åˆ«ä¿å­˜ç…§ç‰‡ ==========
        category_dir = f"{self.training_dir}/{label}"
        os.makedirs(category_dir, exist_ok=True)
        new_path = f"{category_dir}/photo_{os.path.basename(self.photo_path)}"
        os.rename(self.photo_path, new_path)  # ç§»åŠ¨åˆ°ç±»åˆ«æ–‡ä»¶å¤¹

        # æ·»åŠ åˆ°è®­ç»ƒé›†ï¼ˆä½¿ç”¨æ–°è·¯å¾„ï¼‰
        self.svm.add_sample(new_path, label)
        self.ui.resultLabel.setText(f"å·²æ ‡æ³¨ä¸ºï¼š{label}ï¼Œä¿å­˜è‡³ï¼š{new_path}")
        dialog.close()

    def perform_recognition(self):
        # æ‰§è¡Œè¯†åˆ«
        result = self.svm.predict(self.photo_path)

        # æ›´æ–°ç»“æœæ˜¾ç¤º
        result_text = f"è¯†åˆ«ç»“æœï¼š{result}"
        self.ui.resultLabel.setText(result_text)

    def closeEvent(self, event):
        # Release the camera when the window is closed
        self.cap.release()
        super().closeEvent(event)

    def logger_show(self):
        # æ’å…¥å†…å®¹
        logger_item = {
            'one': '-' * 20, 'two': '-' * 20, 'three': '-' * 20, 'four': '-' * 20,
            'five': ''
        }
        self.ui.tableWidgetAnswer.insertRow(int(self.ui.tableWidgetAnswer.rowCount()))
        self.index += 1
        new_item_one = QTableWidgetItem(logger_item['one'])
        new_item_one.setTextAlignment(Qt.AlignCenter)
        new_item_two = QTableWidgetItem(logger_item['two'])
        new_item_two.setTextAlignment(Qt.AlignCenter)
        new_item_three = QTableWidgetItem(logger_item['three'])
        new_item_three.setTextAlignment(Qt.AlignCenter)
        new_item_four = QTableWidgetItem(logger_item['four'])
        new_item_four.setTextAlignment(Qt.AlignCenter)
        new_item_five = QTableWidgetItem(logger_item['five'])
        new_item_five.setTextAlignment(Qt.AlignCenter)
        self.ui.tableWidgetAnswer.setItem(self.index - 1, 0, new_item_one)
        self.ui.tableWidgetAnswer.setItem(self.index - 1, 1, new_item_two)
        self.ui.tableWidgetAnswer.setItem(self.index - 1, 2, new_item_three)
        self.ui.tableWidgetAnswer.setItem(self.index - 1, 3, new_item_four)
        self.ui.tableWidgetAnswer.setItem(self.index - 1, 4, new_item_five)
        # å®šä½è‡³æœ€æ–°è¡Œ
        self.ui.tableWidgetAnswer.verticalScrollBar().setSliderPosition(self.index)
        # åˆ·æ–°
        QApplication.processEvents()


def recognize():
    print("Recognizing...")




# def main():
#     recognize()


if __name__ == "__main__":
    app = QApplication([])
    gui = Gui()
    gui.ui.show()
    app.exec_()